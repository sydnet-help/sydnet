---
title: "SOCI832: Introduction 1: Introduction to Statistics"

lastmod: 2019-05-10T00:00:00.000Z

draft: false
type: docs
maths: true

output:
  blogdown::html_page:
    toc: true

linktitle: "1.2 Intro: Statistics"
menu:
  docs:
    parent: SOCI832
    weight: 120
---


<div id="TOC">
<ul>
<li><a href="#reading">Reading</a></li>
<li><a href="#concepts">Concepts</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#descriptive-statistics-two-numbers-that-are-as-good-as-a-million">1. Descriptive statistics: two numbers that are as good as a million</a><ul>
<li><a href="#meanmedianmode-the-centre">1.1 Mean/Median/Mode: The centre</a></li>
<li><a href="#standard-deviationinterquartile-range-giving-variation-a-number">1.2 Standard deviation/Interquartile range: Giving variation a number</a><ul>
<li><a href="#standard-deviation">Standard deviation</a></li>
<li><a href="#normal-distribution">Normal distribution</a></li>
<li><a href="#interquartile-range">Interquartile range</a></li>
</ul></li>
<li><a href="#minimummaximum-the-bounds-of-our-data">1.3 Minimum/Maximum: The bounds of our data</a></li>
<li><a href="#percentile-for-categories">1.4 Percentile: For categories</a></li>
<li><a href="#n-number-of-non-missing-cases-did-people-actually-answer-this-question">1.5 N (number of non-missing cases): Did people actually answer this question?</a></li>
</ul></li>
<li><a href="#inferential-statistics-drawing-conclusions-about-the-big-bad-world">2. Inferential statistics: Drawing conclusions about the big bad world</a><ul>
<li><a href="#population-the-big-bad-world-hidden-behind-a-curtain">2.1 Population: The big bad world, hidden behind a curtain</a><ul>
<li><a href="#population-parameter-the-number-we-will-never-know">2.1.1 Population parameter: The number we will never know</a></li>
</ul></li>
<li><a href="#sample-the-mini-world-we-can-really-see-and-touch">2.2 Sample: The mini world we can really see and touch</a><ul>
<li><a href="#sample-statistic-our-approximation-of-the-real-world">2.2.1 Sample statistic: Our approximation of the real world</a></li>
</ul></li>
<li><a href="#hypothesis-testing-how-do-i-know-if-i-am-wrong">2.3 Hypothesis testing: How do I know if I am wrong?</a><ul>
<li><a href="#null-hypothesis-the-hypothesis-that-nothing-is-happening">2.3.1 Null hypothesis: The hypothesis that nothing is happening</a></li>
<li><a href="#sampling-distribution-if-i-could-do-this-survey-1000-times">2.3.2 Sampling distribution: If i could do this survey 1,000 times…</a></li>
<li><a href="#central-limit-theorm-if-you-roll-dice-infinite-times-you-always-get-3.5-on-average">2.3.3 Central limit theorm: If you roll dice infinite times you always get 3.5 (on average)</a></li>
<li><a href="#standard-error-if-i-repeated-this-survey-1000-times-the-answer-would-vary-this-much-holds-up-hands-pretending-to-have-caught-a-big-fish.">2.3.4 Standard error: If I repeated this survey 1,000 times… the answer would vary this much (holds up hands pretending to have caught a big fish).</a></li>
<li><a href="#confidence-interval-the-population-parameter-is-somewhere-between-here-and-here">2.3.5 Confidence interval: The population parameter is somewhere between here and here</a></li>
<li><a href="#p-value-the-chance-im-wrong.-the-chance-nothing-is-happening">2.3.6 p-value: the chance I’m wrong. The chance nothing is happening</a></li>
<li><a href="#effect-size-does-it-really-matter-how-much">2.3.7 Effect size: Does it really matter? How much?</a></li>
</ul></li>
<li><a href="#bivariate-inferential-statistics-when-x-goes-up-does-y-go-up">2.4 Bivariate inferential statistics: When X goes up, does Y go up?</a><ul>
<li><a href="#correlation-comparison-of-means-chi-squared">2.4.1 Correlation, comparison of means, chi-squared</a></li>
</ul></li>
<li><a href="#multivariate-inferential-statistics-but-what-about-z-modelling-many-causes.">2.5 Multivariate inferential statistics: “But what about Z?” Modelling many ‘causes’.</a><ul>
<li><a href="#linear-and-logistic-regression">2.5.1 Linear and logistic regression</a></li>
</ul></li>
<li><a href="#dimension-reduction-finding-categories-in-your-data.">2.6 Dimension reduction: Finding categories in your data.</a><ul>
<li><a href="#factor-analysis-cluster-analysis">2.6.1 Factor analysis, Cluster analysis</a></li>
</ul></li>
</ul></li>
<li><a href="#additional-resources">Additional Resources</a></li>
</ul>
</div>

<style>
table, th, td, tr, tbody {
  border-top: 1px solid LightGray;
    border-left: 0px solid LightGray;  
    border-right: 0px solid LightGray;  
    border-bottom: 1px solid LightGray;
    font-size: 0.7rem;
}
</style>
<table>
<tr>
<td>
<div id="reading" class="section level1">
<h1>Reading</h1>
<p><a href="http://a.co/2jVI7VH">Field, A., Miles, J., and Field, Z. (2012). <em>Discovering statistics using R</em>. Sage publications.</a></p>
<ul>
<li>Chapter 2: Everything you ever wanted to know about statistics (well, sort of)</li>
</ul>
</td>
</tr>
</table>
</div>
<div id="concepts" class="section level1">
<h1>Concepts</h1>
<p><b style="padding-left: 2em">Descriptive statistics<br></b> <b style="padding-left: 4em">Mean/Median/Mode (Central tendency)<br></b> <b style="padding-left: 4em">Standard deviation/Interquartile range (Variation/dispersion)<br></b> <b style="padding-left: 4em">Minimum/Maximum<br></b> <b style="padding-left: 4em">Percentile<br></b> <b style="padding-left: 4em">N (number of non-missing cases)<br></b> <b style="padding-left: 2em">Inferential statistics<br></b> <b style="padding-left: 4em">Population<br></b> <b style="padding-left: 6em">Population parameter<br></b> <b style="padding-left: 4em">Sample<br></b> <b style="padding-left: 6em">Sample statistic<br></b> <b style="padding-left: 4em">Hypothesis testing<br></b> <b style="padding-left: 6em">Null hypothesis<br></b> <b style="padding-left: 6em">Sampling distribution<br></b> <b style="padding-left: 6em">Central limit theorm<br></b> <b style="padding-left: 6em">Standard error<br></b> <b style="padding-left: 6em">Confidence interval<br></b> <b style="padding-left: 6em">p-value<br></b> <b style="padding-left: 6em">Effect size<br></b> <b style="padding-left: 4em">Bivariate inferential statistics<br></b> <b style="padding-left: 6em">Correlation, comparison of means, chi-squared<br></b> <b style="padding-left: 4em">Multivariate inferential statistics<br></b> <b style="padding-left: 6em">Linear and logistic regression<br></b> <b style="padding-left: 4em">Dimension reduction and finding categories<br></b> <b style="padding-left: 6em">Factor analysis, Cluster analysis<br></b></p>
<table>
<tr>
<td>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Descriptive statistics Mean/Median/Mode (Central tendency) Standard deviation/Interquartile range (Variation/dispersion) Minimum/Maximum Percentile N (number of non-missing cases) Inferential statistics Population Population parameter Sample Sample statistic Hypothesis testing Null hypothesis Sampling distribution Central limit theorm Standard error Confidence interval p-value Effect size Bivariate inferential statistics Correlation, comparison of means, chi-squared Multivariate inferential statistics Linear and logistic regression Dimension reduction and finding categories Factor analysis, Cluster analysis</p>
</td>
</tr>
</table>
</div>
<div id="descriptive-statistics-two-numbers-that-are-as-good-as-a-million" class="section level1">
<h1>1. Descriptive statistics: two numbers that are as good as a million</h1>
<p>In this course I assume you are allergic to maths. This brings us all to the same level, and it also makes sure all of us try to build on solid foundations.</p>
<p>When we use maths for social sciences, we generally use it in one of two ways: to generate <strong>descriptive statistics</strong> - which allow us to summarise a large amount of data in a few numbers - or to generate <strong>inferential statistics</strong> - which allow us to draw conclusions about the wider world based on a tiny sample of that world.</p>
<p><strong>Descriptive statistics</strong> allow us to summarise a group we can actually see, touch, and/or count. It helps us turn, for example, the incomes of 23 million Australian’s who did the 2016 census into a single number - the median personal weekly personal income of people aged 15 years and over: <a href="https://quickstats.censusdata.abs.gov.au/census_services/getproduct/census/2016/quickstat/036">$662.</a></p>
<div id="meanmedianmode-the-centre" class="section level2">
<h2>1.1 Mean/Median/Mode: The centre</h2>
<p>One type of descriptive statistics try to summarise the “centre” of a dataset (or more correctly, the centre of the values of a variable). The most common example of this is the <strong>average</strong> - formally called <strong>mean</strong> - of a set of numbers.</p>
<p>Other measures of the central tendency are the <strong>median</strong>, and the <strong>mode</strong>. Box 1 provides definitions, uses, and examples.</p>
<p>All of these measures of the central tendency have a common characteristic: they are trying to find <strong>one number that can represent them all.</strong> It’s like running a talent contest to find the ‘most ordinary, normal, typical Australian’, except in this case you are trying to find the ‘most ordinary, normal, typical number in this set’.</p>
<table>
<tr>
<td>
<p style="font-size: 0.8rem;">
<strong>Box 1: Definitions, uses, and examples of mean, median, and mode</strong>
</p>
<p><strong>Mean</strong> (the arithmetic mean): The average. The sum of all cases divided by the number of cases. <br> The mean is good for summarising the centre of a set of numbers that are <strong>normally distributed</strong> (we will learn about this later). For example, height is normally distributed, so the mean is a good summary measure for a group of people’s heights.</p>
<p><strong>Median</strong>: The middle point in a set of numbers. If we order a set of numbers from highest to lowest, and find the number in the middle, this is the median. If two numbers are in the middle (there is an even number of cases), then the median is the average to the two numbers. <br> The median is good for summarising the centre of a set of numbers that is <strong>skewed</strong> (i.e. there are a large number of small values, or a large number of large values). For example, income is highly skewed - i.e. unequally distributed, with a large number of poor people, and a few people who are very very rich - and the median is a better measure of this. In Australia the mean income is around <span>$</span>80,000/year, while the median closer to <span>$</span>50,000/year.</p>
<p><strong>Mode</strong>: The most common number in a set. <br> The mode is good for summarising the centre of a set of numbers that are not ordered. For example, if we have a list of 40,000 students and Macquarie Uni, and a variable which is the name of their degree, it doesn’t make sense to talk about the mean or median of the ‘degree’. However the ‘mode’ makes sense. In every day language, we would say the most common degree at Macquarie University is an Arts Degree. Another way to say this, is the ‘mode’ degree is an Arts Degree.</p>
</td>
</tr>
</table>
</div>
<div id="standard-deviationinterquartile-range-giving-variation-a-number" class="section level2">
<h2>1.2 Standard deviation/Interquartile range: Giving variation a number</h2>
<p>We know from life, however, that the ‘most ordinary, normal, typical’ single example of anything is a gross simplication.</p>
<p>All sets have variety, and the second major type of descriptive statistic tries to capture this variety, and do it in just one number.</p>
<div id="standard-deviation" class="section level3">
<h3>Standard deviation</h3>
<p>The most common measure of variety - or technically ‘variability’, ‘variation’, or ‘dispersion’ - in a set of numbers is probably the <strong>standard deviation</strong>.</p>
<p>Box 2 provides an explanation of standard deviation - as equation, and also in everyday language.</p>
<p>Intiutively - not strickly - you can think of <strong>standard deviation</strong> as the average amount - as an absolute value (so negative become positive, and positive stay positive) - that each person’s value for a variable ‘misses’ (deviates) from the mean of the variable.</p>
<p>If the standard deviation is close to zero, then virtually everyone in the dataset has the same value for the variable.</p>
<p>If the standard deviation is large, then you expect that - on average - any particular person you pick from the dataset is going to be quite distant from (greater or lesser than) the mean.</p>
</div>
<div id="normal-distribution" class="section level3">
<h3>Normal distribution</h3>
</div>
<div id="interquartile-range" class="section level3">
<h3>Interquartile range</h3>
<p>While standard deviation is a good measure of variablity for</p>
<table>
<tr>
<td>
<p style="font-size: 0.8rem;">
<strong>Box 2: Standard Deviation as equation and everyday language</strong>
</p>
<p><span class="math inline">\(\begin{aligned} \text{Standard Deviation of variable x} = &amp;\sqrt{\frac{\sum_{i=1}^n (x_i - \bar x)^2}{N}}\\ \\ \text{Where:} \\ x_i = &amp;\text{value of x for each individual i} \\ \sum_{i=1}^n = &amp;\text{sum for all observations from 1 to n} \\ \bar x = &amp;\text{ mean of x} \\ N = &amp;\text{ number of observations} \\ \end{aligned}\)</span></p>
<p>While this equation looks scary to many people, I think the best way to break it down - conceptually, and by analogy, not strict mathematically - is to think about this as having just three main parts:</p>
<ul>
<li><strong>Variation from mean</strong>: First, it basically asks how much, for each value of a variable (e.g. the age of any particular student in a class) varies from the mean for the whole set (e.g. the average age of the class). This is represented in the equation as: <span class="math display">\[(x_i - \bar x)\]</span></li>
<li><strong>Averaged over all individuals</strong>: Second, it takes the average (mean) of this across all observations in the dataset (e.g. all students in the class). This is represented by the sum of (the funny E) divided by N: <span class="math display">\[\frac{\sum_{i=1}^n \text{variation from mean} }{N}\]</span></li>
<li><strong>Punishing (counting) big variations more than small ones</strong>: Third, it actually squares the deviation from the mean - which has the effect of ‘punishing’ (i.e. inflating or more heavily weighting) larger deviations from the mean more. It then takes the square root of the whole thing, basically to counter act the effect of the squaring, and make it all measured in the same ‘units’ as the mean.</li>
</ul>
<p>BUT, the take away from all this is: the standard deviation is - more or less - the average amount all members of a dataset vary from the mean.</p>
<p>For example, you have two classes of 100 students each, and the average age of both classes individually is 22, but the standard deviation of one class is zero, and the other is one.</p>
<p>Based on this standard deviation, you would know that - <strong>roughly</strong> and <strong>on average</strong> - if you picked any, say, 10 students from each class: * the tens students from the class with zero standard deviation would all be aged 22, while * the ten students from class with one year standard deviation, would be comprised of students who - on average - deviate from the mean age by one year (i.e. some students will be 19, 20, 21, 23, 24, etc.).</p>
</td>
</tr>
</table>
</div>
</div>
<div id="minimummaximum-the-bounds-of-our-data" class="section level2">
<h2>1.3 Minimum/Maximum: The bounds of our data</h2>
</div>
<div id="percentile-for-categories" class="section level2">
<h2>1.4 Percentile: For categories</h2>
</div>
<div id="n-number-of-non-missing-cases-did-people-actually-answer-this-question" class="section level2">
<h2>1.5 N (number of non-missing cases): Did people actually answer this question?</h2>
</div>
</div>
<div id="inferential-statistics-drawing-conclusions-about-the-big-bad-world" class="section level1">
<h1>2. Inferential statistics: Drawing conclusions about the big bad world</h1>
<div id="population-the-big-bad-world-hidden-behind-a-curtain" class="section level2">
<h2>2.1 Population: The big bad world, hidden behind a curtain</h2>
<div id="population-parameter-the-number-we-will-never-know" class="section level3">
<h3>2.1.1 Population parameter: The number we will never know</h3>
</div>
</div>
<div id="sample-the-mini-world-we-can-really-see-and-touch" class="section level2">
<h2>2.2 Sample: The mini world we can really see and touch</h2>
<div id="sample-statistic-our-approximation-of-the-real-world" class="section level3">
<h3>2.2.1 Sample statistic: Our approximation of the real world</h3>
</div>
</div>
<div id="hypothesis-testing-how-do-i-know-if-i-am-wrong" class="section level2">
<h2>2.3 Hypothesis testing: How do I know if I am wrong?</h2>
<div id="null-hypothesis-the-hypothesis-that-nothing-is-happening" class="section level3">
<h3>2.3.1 Null hypothesis: The hypothesis that nothing is happening</h3>
</div>
<div id="sampling-distribution-if-i-could-do-this-survey-1000-times" class="section level3">
<h3>2.3.2 Sampling distribution: If i could do this survey 1,000 times…</h3>
</div>
<div id="central-limit-theorm-if-you-roll-dice-infinite-times-you-always-get-3.5-on-average" class="section level3">
<h3>2.3.3 Central limit theorm: If you roll dice infinite times you always get 3.5 (on average)</h3>
</div>
<div id="standard-error-if-i-repeated-this-survey-1000-times-the-answer-would-vary-this-much-holds-up-hands-pretending-to-have-caught-a-big-fish." class="section level3">
<h3>2.3.4 Standard error: If I repeated this survey 1,000 times… the answer would vary this much (holds up hands pretending to have caught a big fish).</h3>
</div>
<div id="confidence-interval-the-population-parameter-is-somewhere-between-here-and-here" class="section level3">
<h3>2.3.5 Confidence interval: The population parameter is somewhere between here and here</h3>
</div>
<div id="p-value-the-chance-im-wrong.-the-chance-nothing-is-happening" class="section level3">
<h3>2.3.6 p-value: the chance I’m wrong. The chance nothing is happening</h3>
</div>
<div id="effect-size-does-it-really-matter-how-much" class="section level3">
<h3>2.3.7 Effect size: Does it really matter? How much?</h3>
</div>
</div>
<div id="bivariate-inferential-statistics-when-x-goes-up-does-y-go-up" class="section level2">
<h2>2.4 Bivariate inferential statistics: When X goes up, does Y go up?</h2>
<div id="correlation-comparison-of-means-chi-squared" class="section level3">
<h3>2.4.1 Correlation, comparison of means, chi-squared</h3>
</div>
</div>
<div id="multivariate-inferential-statistics-but-what-about-z-modelling-many-causes." class="section level2">
<h2>2.5 Multivariate inferential statistics: “But what about Z?” Modelling many ‘causes’.</h2>
<div id="linear-and-logistic-regression" class="section level3">
<h3>2.5.1 Linear and logistic regression</h3>
</div>
</div>
<div id="dimension-reduction-finding-categories-in-your-data." class="section level2">
<h2>2.6 Dimension reduction: Finding categories in your data.</h2>
<div id="factor-analysis-cluster-analysis" class="section level3">
<h3>2.6.1 Factor analysis, Cluster analysis</h3>
</div>
</div>
</div>
<div id="additional-resources" class="section level1">
<h1>Additional Resources</h1>
<p><a href="link">Reference</a></p>
<p><a href="link">Reference</a></p>
<center>
Last updated on <em>05 July, 2019</em> by <em>Dr Nicholas Harrigan</em> <a href="mailto:nicholas.harrigan@mq.edu.au">(nicholas.harrigan@mq.edu.au)</a>
</center>
</div>
